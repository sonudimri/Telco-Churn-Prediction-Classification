{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d8cae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d0d201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Helper function\n",
    "\n",
    "def one_hot_encode(data, categorical_columns, drop_first=False, drop_original=True):\n",
    "    encoded_data = data.copy()  # Create a copy of the original data\n",
    "    \n",
    "    for column_name in categorical_columns:\n",
    "        unique_categories = data[column_name].unique()  # Get unique categories\n",
    "        \n",
    "        for category in unique_categories:\n",
    "            new_column_name = f'{column_name}_{category}'  # Create a new column name\n",
    "            \n",
    "            # Apply one-hot encoding, with or without dropping the first category\n",
    "            encoded_data[new_column_name] = (data[column_name] == category).astype(int)\n",
    "            \n",
    "            # If drop_first is True, drop the first category's column\n",
    "            if drop_first and category == unique_categories[0]:\n",
    "                encoded_data.drop(columns=new_column_name, inplace=True)\n",
    "    \n",
    "    # If drop_original is True, drop the original categorical columns\n",
    "    if drop_original:\n",
    "        encoded_data.drop(columns=categorical_columns, inplace=True)\n",
    "    \n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "def data_preprocessing_logistic(df):\n",
    "\n",
    "    ## Dropping column which are not significant\n",
    "    df1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\n",
    "\n",
    "    ## getting missing Values\n",
    "    df1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "\n",
    "    ## Encoding\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    df1['Churn']=le.fit_transform(df1['Churn'])\n",
    "\n",
    "    df1[['MultipleLines','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['MultipleLines','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n",
    "    df1[['MultipleLines']]= df1[['MultipleLines']].replace('No phone service','No')\n",
    "\n",
    "    ## Treating Missing Values\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "\n",
    "    df1['TotalCharges'] = imputer.fit_transform(df1[['TotalCharges']])\n",
    "\n",
    "\n",
    "    X= df1.drop('Churn', axis=1)\n",
    "    y= df1['Churn']\n",
    "\n",
    "    for col in X.columns:\n",
    "        col_type = X[col].dtype\n",
    "        if col_type == 'object' or col_type.name == 'category':\n",
    "            X[col] = X[col].astype('category')\n",
    "            \n",
    "    numerical= X.select_dtypes('number').columns\n",
    "\n",
    "    categorical = X.select_dtypes('category').columns\n",
    "    \n",
    "    #X = one_hot_encode(X, categorical, drop_first=True, drop_original=True)\n",
    "    \n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5cb12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e27ef2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data_preprocessing_logistic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344b692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X)\n",
    "df1 = pd.concat((X,y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c6a731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ec56b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen Partner Dependents  tenure MultipleLines InternetService  \\\n",
       "0              0     Yes         No       1            No             DSL   \n",
       "1              0      No         No      34            No             DSL   \n",
       "2              0      No         No       2            No             DSL   \n",
       "3              0      No         No      45            No             DSL   \n",
       "4              0      No         No       2            No     Fiber optic   \n",
       "\n",
       "  OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV  \\\n",
       "0             No          Yes               No          No          No   \n",
       "1            Yes           No              Yes          No          No   \n",
       "2            Yes          Yes               No          No          No   \n",
       "3            Yes           No              Yes         Yes          No   \n",
       "4             No           No               No          No          No   \n",
       "\n",
       "  StreamingMovies        Contract PaperlessBilling              PaymentMethod  \\\n",
       "0              No  Month-to-month              Yes           Electronic check   \n",
       "1              No        One year               No               Mailed check   \n",
       "2              No  Month-to-month              Yes               Mailed check   \n",
       "3              No        One year               No  Bank transfer (automatic)   \n",
       "4              No  Month-to-month              Yes           Electronic check   \n",
       "\n",
       "   MonthlyCharges  TotalCharges  Churn  \n",
       "0           29.85         29.85      0  \n",
       "1           56.95       1889.50      0  \n",
       "2           53.85        108.15      1  \n",
       "3           42.30       1840.75      0  \n",
       "4           70.70        151.65      1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()\n",
    "# no --> 0\n",
    "# yes --> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fc5d9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Churn', ylabel='count'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df1, x = \"Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39ce3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "oht = OneHotEncoder()\n",
    "ohe_df1 = pd.get_dummies(df1, drop_first = True)\n",
    "\n",
    "X = ohe_df1.drop([\"Churn\"], axis=1)\n",
    "y = ohe_df1[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfb64589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8176011355571328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1036\n",
      "           1       0.69      0.56      0.62       373\n",
      "\n",
      "    accuracy                           0.82      1409\n",
      "   macro avg       0.77      0.73      0.75      1409\n",
      "weighted avg       0.81      0.82      0.81      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have your data loaded into X (features) and y (target variable)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "718ddef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.716820440028389\n",
      "Precision: 0.7165776563479768\n",
      "Recall: 0.716820440028389\n",
      "F1 Score: 0.7166986885041116\n",
      "Confusion Matrix:\n",
      " [[837 199]\n",
      " [200 173]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1036\n",
      "           1       0.47      0.46      0.46       373\n",
      "\n",
      "    accuracy                           0.72      1409\n",
      "   macro avg       0.64      0.64      0.64      1409\n",
      "weighted avg       0.72      0.72      0.72      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4919be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794889992902768\n",
      "Precision: 0.7819623945311586\n",
      "Recall: 0.794889992902768\n",
      "F1 Score: 0.7824667336016841\n",
      "Confusion Matrix:\n",
      " [[946  90]\n",
      " [199 174]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1036\n",
      "           1       0.66      0.47      0.55       373\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.74      0.69      0.71      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68c9c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k: 16\n",
      "Accuracy: 0.7913413768630234\n",
      "Precision: 0.7778399515355695\n",
      "Recall: 0.7913413768630234\n",
      "F1 Score: 0.7680756559200422\n",
      "Confusion Matrix:\n",
      " [[975  61]\n",
      " [233 140]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87      1036\n",
      "           1       0.70      0.38      0.49       373\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.75      0.66      0.68      1409\n",
      "weighted avg       0.78      0.79      0.77      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a list to store cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Define a range of k values\n",
    "k_values = list(range(1, 21))\n",
    "\n",
    "# Perform cross-validation for each k\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Find the best value of k\n",
    "best_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "\n",
    "# Initialize the KNN classifier with the best k\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best k value\n",
    "print(\"Best value of k:\", best_k)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4455ad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      1036\n",
      "           1       0.58      0.57      0.58       373\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.71      0.71      1409\n",
      "weighted avg       0.78      0.78      0.78      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the resampled training data\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e870cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k: 1\n",
      "Accuracy: 0.709013484740951\n",
      "Precision: 0.733260789454861\n",
      "Recall: 0.709013484740951\n",
      "F1 Score: 0.7182261987664014\n",
      "Confusion Matrix:\n",
      " [[785 251]\n",
      " [159 214]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79      1036\n",
      "           1       0.46      0.57      0.51       373\n",
      "\n",
      "    accuracy                           0.71      1409\n",
      "   macro avg       0.65      0.67      0.65      1409\n",
      "weighted avg       0.73      0.71      0.72      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize a list to store cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Define a range of k values\n",
    "k_values = list(range(1, 21))\n",
    "\n",
    "# Perform cross-validation for each k\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Find the best value of k\n",
    "best_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "\n",
    "# Initialize the KNN classifier with the best k\n",
    "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best k value\n",
    "print(\"Best value of k:\", best_k)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5466efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7253371185237757\n",
      "Precision: 0.7420177129840463\n",
      "Recall: 0.7253371185237757\n",
      "F1 Score: 0.7320655852923456\n",
      "Confusion Matrix:\n",
      " [[809 227]\n",
      " [160 213]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81      1036\n",
      "           1       0.48      0.57      0.52       373\n",
      "\n",
      "    accuracy                           0.73      1409\n",
      "   macro avg       0.66      0.68      0.67      1409\n",
      "weighted avg       0.74      0.73      0.73      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ae37015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7757274662881476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1036\n",
      "           1       0.56      0.69      0.62       373\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.75      0.73      1409\n",
      "weighted avg       0.80      0.78      0.78      1409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshaykarhana/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have your data loaded into X (features) and y (target variable)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predicting on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b26d5",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "##### Logistic would be our final model as its Recall for 1 is coming out to be 0.69 better than other 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eada6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
